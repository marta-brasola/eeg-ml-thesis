{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path = \"/home/marta/Documenti/eeg-ml-thesis/\"\n",
    "os.chdir(path)\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim \n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import numpy as np \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import r_pca \n",
    "import scipy.io\n",
    "from tqdm import tqdm\n",
    "import datetime \n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay \n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copute Crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def precompute_crops(subject_list, window, overlap, DATASET_DIR, num_columns=16, train_dataset=None):\n",
    "    \n",
    "\n",
    "    if train_dataset == True:\n",
    "        save_dir = \"/home/marta/Documenti/eeg-ml-thesis/alessandrini-train\"\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "    elif train_dataset == False:\n",
    "        save_dir = \"/home/marta/Documenti/eeg-ml-thesis/alessandrini-test\"\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    for subject_id, category_label in subject_list:\n",
    "        file_path = f\"{DATASET_DIR}/S{subject_id}_{category_label}.npz\"\n",
    "        save_path = f\"{save_dir}/S{subject_id}_{category_label}_crops.npz\"\n",
    "\n",
    "        # if os.path.exists(save_path): \n",
    "        #    print(f\"Skipping {subject_id}, crops already exist.\")\n",
    "        #    continue\n",
    "\n",
    "        eeg = np.load(file_path)['eeg'].T \n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        eeg = scaler.fit_transform(eeg)\n",
    "\n",
    "        num_windows = (len(eeg) - window) // (window - overlap) + 1\n",
    "        x_data = np.empty((num_windows, window, num_columns))\n",
    "\n",
    "        i = 0\n",
    "        for w in range(num_windows):\n",
    "            x_data[w] = eeg[i:i + window]\n",
    "            i += (window - overlap)\n",
    "\n",
    "        y_data = np.full((num_windows, 1), (category_label == 'AD')) \n",
    "\n",
    "        np.savez(save_path, x_data=x_data, y_data=y_data)\n",
    "        # print(f\"Saved crops for {subject_id} at {save_path}\")\n",
    "\n",
    "\n",
    "def load_npz_data(directory):\n",
    "\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith(\".npz\"):  \n",
    "            file_path = os.path.join(directory, file)\n",
    "            data = np.load(file_path)\n",
    "            \n",
    "            x_list.append(data['x_data'])  \n",
    "            y_list.append(data['y_data'])  \n",
    "\n",
    "    x_data = np.vstack(x_list) if x_list else np.array([])\n",
    "    y_data = np.vstack(y_list) if y_list else np.array([])\n",
    "\n",
    "    return x_data, y_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_val(dataset, test_size=0.2, random_state=42):\n",
    "    train_indices, val_indices = train_test_split(\n",
    "        range(len(dataset.crops_index)), \n",
    "        test_size=test_size,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    return train_indices, val_indices \n",
    "\n",
    "def pca_reduction(A, tol, comp = 0):\n",
    "  rpca = False\n",
    "  rpca_mu = 0\n",
    "  multiscale_pca = False\n",
    "\n",
    "  assert(len(A.shape) == 2)\n",
    "  dmin = min(A.shape)\n",
    "  if rpca:\n",
    "    r = r_pca.R_pca(A, mu = rpca_mu)\n",
    "    print('Auto tol:', 1e-7 * r.frobenius_norm(r.D), 'used tol:', tol)\n",
    "    print('mu', r.mu, 'lambda', r.lmbda)\n",
    "    L, S = r.fit(tol = tol, max_iter = 10, iter_print = 1)\n",
    "    global norm_s\n",
    "    norm_s = np.linalg.norm(S, ord='fro')  # for debug\n",
    "    print('||A,L,S||:', np.linalg.norm(A, ord='fro'), np.linalg.norm(L, ord='fro'), np.linalg.norm(S, ord='fro'))\n",
    "    #np.savez_compressed('rpca.npz', pre = A, post = L)\n",
    "  elif multiscale_pca:\n",
    "    print('MSPCA...')\n",
    "    #ms = mspca.MultiscalePCA()\n",
    "    #L = ms.fit_transform(A, wavelet_func='sym4', threshold=0.1, scale = True )\n",
    "    print('saving MAT file and calling Matlab...')\n",
    "    scipy.io.savemat('mspca.mat', {'A': A}, do_compression = True)\n",
    "    os.system('matlab -batch \"mspca(\\'mspca.mat\\')\"')\n",
    "    L = scipy.io.loadmat('mspca.mat')['L'] \n",
    "  else:\n",
    "    \n",
    "    L = A\n",
    "  U, lam, V = np.linalg.svd(L, full_matrices = False)  # V is transposed\n",
    "  assert(U.shape == (A.shape[0], dmin) and lam.shape == (dmin,) and V.shape == (dmin, A.shape[1]))\n",
    "  #np.savetxt('singular_values.csv', lam)\n",
    "  lam_trunc = lam[lam > 0.015 * lam[0]]  # magic number\n",
    "  p = comp if comp else len(lam_trunc)\n",
    "  assert(p <= dmin)\n",
    "  print('PCA truncation', dmin, '->', p)\n",
    "  return L, V.T[:,:p]\n",
    "\n",
    "def reduce_matrix(A, V, PCA_COMPONENTS):\n",
    "  # (N, w, 16) → (N, 16, w) → ((N*16), w) → compute V\n",
    "  # (N, 16, w) * V → transpose again last dimensions\n",
    "  B = np.swapaxes(A, 1, 2)  # (N, 16, w)\n",
    "  C = B.reshape((-1, B.shape[2]))  # ((N*16), w)\n",
    "  if V is None:\n",
    "    L, V = pca_reduction(C, 5e-6, comp = PCA_COMPONENTS)\n",
    "  B = C @ V  # ((N*16), p)\n",
    "  B = B.reshape((A.shape[0], A.shape[2], B.shape[1]))  # (N, 16, p)\n",
    "  return np.swapaxes(B, 1, 2), V  # B = (N, p, 16)\n",
    "\n",
    "def adjust_size(x, y):\n",
    "  # when flattening the data matrix on the first dimension, y must be made compatible\n",
    "  if len(x) == len(y): return y\n",
    "  factor = len(x) // len(y)\n",
    "  ynew = np.empty((len(x), 1))\n",
    "  for i in range(0, len(y)):\n",
    "    ynew[i * factor : (i + 1) * factor] = y[i]\n",
    "  return ynew\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling\n",
    "\n",
    "Oversampling only on trainig dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversampling(x_data, y_data, num_classes=2):\n",
    "  # Duplicate inputs with classes occurring less, so to have a more balanced distribution.\n",
    "  # It operates on single data windows, so use it on data that have already been split\n",
    "  #  by subject (typically only on training data).\n",
    "  x_data_over = x_data.copy()\n",
    "  y_data_over = y_data.copy()\n",
    "  occurr = [np.sum(y_data == cl) for cl in range(0, num_classes)]\n",
    "  for cl in range(0, num_classes):\n",
    "    if occurr[cl] == max(occurr):\n",
    "      continue\n",
    "    mask = y_data[:, 0] == cl\n",
    "    x_dup = x_data[mask].copy()\n",
    "    y_dup = y_data[mask].copy()\n",
    "    while occurr[cl] < max(occurr):\n",
    "      x_dup_jitter = x_dup + np.random.normal(scale=0.03, size=x_dup.shape)\n",
    "      how_many = min(len(y_dup), max(occurr) - occurr[cl])\n",
    "      x_data_over = np.vstack((x_data_over, x_dup_jitter[:how_many]))\n",
    "      y_data_over = np.vstack((y_data_over, y_dup[:how_many]))\n",
    "      occurr[cl] += how_many\n",
    "  return x_data_over, y_data_over"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlessandriniEegDataset(Dataset):\n",
    "    def __init__(self, x_data, y_data):\n",
    "        self.x_data = x_data\n",
    "        self.y_data = y_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x_data[idx], self.y_data[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LSTMModel(nn.Module):\n",
    "#     def __init__(self, input_dim, hidden_dim, output_dim, num_layers=1, dropout_prob=0.5):\n",
    "#         super(LSTMModel, self).__init__()\n",
    "        \n",
    "#         ##TODO aggiungere un layer di flatten per processare la sequenza in maniera temporale \n",
    "#         self.lstm1 = nn.LSTM(input_dim, hidden_dim, num_layers=num_layers, batch_first=True)\n",
    "        \n",
    "#         self.dropout1 = nn.Dropout(dropout_prob)\n",
    "        \n",
    "#         self.lstm2 = nn.LSTM(hidden_dim, hidden_dim, num_layers=num_layers, batch_first=True)\n",
    "        \n",
    "#         self.dropout2 = nn.Dropout(dropout_prob)\n",
    "        \n",
    "#         self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # layer di attivazione\n",
    "        \n",
    "#         # x = x.squeeze(0)  \n",
    "#         out, (hn, cn) = self.lstm1(x)\n",
    "        \n",
    "#         out = self.dropout1(out)\n",
    "        \n",
    "#         out, (hn, cn) = self.lstm2(out)\n",
    "        \n",
    "#         out = self.dropout2(out[:, -1, :])  \n",
    "        \n",
    "#         out = self.fc(out)\n",
    "        \n",
    "#         # out = F.log_softmax(out, dim=1) uso la loss cross entropy\n",
    "        \n",
    "#         return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers=1, dropout_prob=0.5, use_dense1=False):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        \n",
    "        # Optional Dense Layer Before LSTM (matches TensorFlow's `dense1`)\n",
    "        self.use_dense1 = use_dense1\n",
    "        if use_dense1:\n",
    "            self.dense1 = nn.Linear(input_dim, hidden_dim)\n",
    "        \n",
    "        # First LSTM Layer (returns full sequence if second LSTM exists)\n",
    "        self.lstm1 = nn.LSTM(hidden_dim if use_dense1 else input_dim, hidden_dim, num_layers=num_layers, \n",
    "                             batch_first=True, dropout=dropout_prob if num_layers > 1 else 0, \n",
    "                             bidirectional=False)\n",
    "\n",
    "        self.dropout1 = nn.Dropout(dropout_prob) \n",
    "\n",
    "        # Second LSTM Layer (if present, returns last output)\n",
    "        self.lstm2 = nn.LSTM(hidden_dim, hidden_dim, num_layers=num_layers, batch_first=True, \n",
    "                             dropout=dropout_prob if num_layers > 1 else 0) \n",
    "\n",
    "        self.dropout2 = nn.Dropout(dropout_prob)\n",
    "\n",
    "        # Fully Connected Output Layer (No Softmax, since CrossEntropyLoss expects logits)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.use_dense1:\n",
    "            x = self.dense1(x)\n",
    "        \n",
    "        # First LSTM layer\n",
    "        out, _ = self.lstm1(x)\n",
    "        out = self.dropout1(out)\n",
    "\n",
    "        # Second LSTM layer (keeps last output only)\n",
    "        out, _ = self.lstm2(out)\n",
    "        out = self.dropout2(out[:, -1, :])  # Keep only last timestep\n",
    "        \n",
    "        # Fully connected output\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out  # No softmax, since PyTorch's CrossEntropyLoss applies it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_pred, y_true):\n",
    "  \n",
    "  correct = (y_pred == y_true).sum().item()\n",
    "  \n",
    "  return correct / y_true.size(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_pred, y_true):\n",
    "  \n",
    "  correct = (y_pred == y_true).sum().item()\n",
    "  \n",
    "  return correct / y_true.size(0)\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "  print(\"starting training loop\")\n",
    "  \n",
    "  \"\"\"\n",
    "  Define Training Step\n",
    "  \"\"\"\n",
    "  \n",
    "  model.train()\n",
    "  \n",
    "  train_loss = 0.0\n",
    "  pred_list = []\n",
    "  gt_list = []\n",
    "  \n",
    "  \n",
    "  for batch_idx, (data, target) in enumerate(tqdm(train_loader)):\n",
    "\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    output = model(data)\n",
    "    \n",
    "\n",
    "    target = target.squeeze().long()\n",
    "\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    loss = criterion(output, target)\n",
    "    train_loss += loss.item()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    _, y_pred = torch.max(output,1)\n",
    "    \n",
    "    pred_list.append(y_pred)\n",
    "    gt_list.append(target)\n",
    "    \n",
    "  pred_list = torch.cat(pred_list)\n",
    "  gt_list = torch.cat(gt_list)\n",
    "  \n",
    "  train_acc = calculate_accuracy(pred_list, gt_list) \n",
    "  print(\"ended training step\")\n",
    "  return train_loss / len(train_loader), train_acc, pred_list, gt_list \n",
    "\n",
    "def validation(model, device, val_loader):\n",
    "  print(\"starting validation step\")\n",
    "  \n",
    "  \"\"\"\n",
    "  Define Validation Step\n",
    "  \"\"\"\n",
    "    \n",
    "  model.eval()\n",
    "  \n",
    "  val_loss = 0   \n",
    "  pred_list = []\n",
    "  gt_list = []\n",
    "\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  \n",
    "  with torch.no_grad():\n",
    "    \n",
    "    for data, target in val_loader:\n",
    "        \n",
    "      data, target = data.to(device), target.to(device).squeeze().long()\n",
    "      output = model(data)\n",
    "      loss = criterion(output, target)\n",
    "      val_loss += loss.item()\n",
    "      _, y_pred = torch.max(output,1)\n",
    "      \n",
    "      pred_list.append(y_pred)\n",
    "      gt_list.append(target)\n",
    "      # correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "      \n",
    "  pred_list = torch.cat(pred_list)\n",
    "  gt_list = torch.cat(gt_list)\n",
    "           \n",
    "  val_acc = calculate_accuracy(pred_list, gt_list)\n",
    "  \n",
    "  \n",
    "  return val_loss / len(val_loader.dataset), val_acc, pred_list, gt_list \n",
    "     \n",
    " \n",
    "def test_and_save_confusion_matrix(model, device, loader,cm_name):\n",
    "    model.eval()\n",
    "    gt_list = []\n",
    "    pred_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device).to(torch.float32), target.to(device).squeeze().long()\n",
    "            output = model(data).float()\n",
    "            _, y_pred = torch.max(output, 1)  \n",
    "            \n",
    "            pred_list.append(y_pred)\n",
    "            gt_list.append(target)\n",
    "            \n",
    "        pred_list = torch.cat(pred_list)\n",
    "        gt_list = torch.cat(gt_list)\n",
    "      \n",
    "    test_acc = calculate_accuracy(pred_list, gt_list)\n",
    "    print(f\"Test Accuracy: {test_acc:.2f}%\")    \n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(gt_list.cpu().numpy(), pred_list.cpu().numpy())\n",
    "    num_classes = cm.shape[0]\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.arange(num_classes))\n",
    "\n",
    "    # Plot and save confusion matrix\n",
    "    disp.plot(cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.savefig(f'output/{cm_name}')\n",
    "    plt.show()   \n",
    "         \n",
    "def save_model(model, optimizer, epoch):\n",
    "    \"\"\"\n",
    "    Function to save model states for a given epoch.\n",
    "    \"\"\"\n",
    "    \n",
    "    model_name = model.__class__.__name__\n",
    "\n",
    "    model_dir = os.path.join(os.getcwd(), \"output\")\n",
    "    os.makedirs(model_dir, exist_ok=True)  # Creates directory if it doesn't exist\n",
    "\n",
    "    # Generate filename with timestamp\n",
    "    now = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    path = os.path.join(model_dir, f\"{model_name}_{now}.pth\")  # Add `.pth` for clarity\n",
    "\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "    }, path)\n",
    "\n",
    "    print(f\"Model saved to {path}\")\n",
    "\n",
    "def save_best_model(model, optimizer, epoch, path):\n",
    "    \"\"\"\n",
    "    Saves the best model based on validation loss.\n",
    "    Overwrites the existing file if the new model is better.\n",
    "    \"\"\"\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "    }, path)\n",
    "\n",
    "    print(f\"Best model saved to {path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: (40602, 256, 16), Labels distribution: [16290 24312]\n",
      "Oversampled dataset size: (48624, 256, 16), Labels distribution: [24312 24312]\n",
      "training data shape: torch.Size([36468, 256, 16])\n",
      "training data shape: torch.Size([36468, 1])\n",
      "validation data shape: torch.Size([12156, 256, 16])\n",
      "validation data shape: torch.Size([12156, 1])\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "DATASET_DIR = \"/home/marta/Documenti/eeg_rnn_repo/rnn-eeg-ad/eeg2\"\n",
    "WINDOW = 256\n",
    "OVERLAP = WINDOW // 2 \n",
    "PCA_COMPONENTS = 50\n",
    "num_epochs = 20\n",
    "\n",
    "# Loading data and computing crops\n",
    "subj_list = (\n",
    "    tuple((f'{i:02d}', 'N') for i in range(1, 16)) +  # normal subjects, S01 to S15\n",
    "    tuple((f'{i:02d}', 'AD') for i in range(1, 21))   # alzheimer's subjects, S01 to S20\n",
    ")\n",
    "subjs_test = (0, 1, 15, 16, 17)  \n",
    "test_subject_list = [subj_list[i] for i in subjs_test]\n",
    "train_val_subjects = [subj for i, subj in enumerate(subj_list) if i not in subjs_test]   \n",
    "\n",
    "precompute_crops(train_val_subjects, window=WINDOW, DATASET_DIR=DATASET_DIR, overlap=OVERLAP, train_dataset=True)\n",
    "precompute_crops(test_subject_list, window=WINDOW, DATASET_DIR=DATASET_DIR, overlap=OVERLAP, train_dataset=False)\n",
    "\n",
    "\n",
    "# Loading crops for oversampling (only training and validation dataset is oversampled)\n",
    "test_path = \"/home/marta/Documenti/eeg-ml-thesis/alessandrini-test\"\n",
    "train_path = \"/home/marta/Documenti/eeg-ml-thesis/alessandrini-train\"\n",
    "\n",
    "X_test, y_test = load_npz_data(test_path)\n",
    "X, y = load_npz_data(train_path)\n",
    "\n",
    "\n",
    "print(f\"Original dataset size: {X.shape}, Labels distribution: {np.bincount(y.flatten())}\")\n",
    "\n",
    "X_over, y_over = oversampling(X, y)\n",
    "\n",
    "print(f\"Oversampled dataset size: {X_over.shape}, Labels distribution: {np.bincount(y_over.flatten())}\")\n",
    "\n",
    "X_over = torch.tensor(X_over).float()\n",
    "y_over = torch.tensor(y_over).float()\n",
    "\n",
    "# Train, val, test split and apply PCA \n",
    "X_train, X_val, y_train, y_val = train_test_split(X_over, y_over, train_size = 0.75, random_state=42, shuffle=True)\n",
    "\n",
    "print(f\"training data shape: {X_train.shape}\")\n",
    "print(f\"training data shape: {y_train.shape}\")\n",
    "print(f\"validation data shape: {X_val.shape}\")\n",
    "print(f\"validation data shape: {y_val.shape}\")\n",
    "\n",
    "\n",
    "X_train, Vpca = reduce_matrix(X_train, None, PCA_COMPONENTS)\n",
    "y_train = adjust_size(X_train, y_train)\n",
    "\n",
    "X_val, _ = reduce_matrix(X_val, Vpca, PCA_COMPONENTS)\n",
    "y_val = adjust_size(X_val, y_val)\n",
    "\n",
    "X_test, _ = reduce_matrix(X_test, Vpca.cpu().numpy() if isinstance(Vpca, torch.Tensor) else Vpca, PCA_COMPONENTS)\n",
    "y_test = adjust_size(X_test, y_test).astype(np.float32)\n",
    "# x_data_test = x_data_test.astype(np.float32)\n",
    "\n",
    "print(f\"training data shape: {X_train.shape}\")\n",
    "print(f\"training data shape: {y_train.shape}\")\n",
    "print(f\"validation data shape: {X_val.shape}\")\n",
    "print(f\"validation data shape: {y_val.shape}\")\n",
    "\n",
    "\n",
    "# Create dataset and Data loader\n",
    "train_dataset = AlessandriniEegDataset(X_train, y_train)\n",
    "val_dataset = AlessandriniEegDataset(X_val, y_val)\n",
    "test_dataset = AlessandriniEegDataset(X_test, y_test)\n",
    "\n",
    "#train_indices, val_indices = split_train_val(dataset_over, test_size=0.2)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "\n",
    "# call model and training\n",
    "input_dim = 16        \n",
    "hidden_dim = 8        \n",
    "output_dim = 2    \n",
    "window_size = 20      \n",
    "dropout_prob = 0.5 \n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "\n",
    "model = LSTMModel(input_dim, hidden_dim, output_dim, dropout_prob=dropout_prob, use_dense1=False)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "# scheduler = StepLR(optimizer, step_size=1)\n",
    "\n",
    "\n",
    "best_val_loss = float('inf')  \n",
    "history = {\n",
    "    \"train_loss\": [],\n",
    "    \"train_acc\": [],\n",
    "    \"val_loss\": [],\n",
    "    \"val_acc\": []\n",
    "}\n",
    "file_name = f\"{WINDOW}_{OVERLAP}_{PCA_COMPONENTS}\"\n",
    "model_name = file_name + \".pth\"\n",
    "best_model_path = os.path.join(os.getcwd(), \"output\", model_name)  \n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    print(f\"\\nProcessing epoch number: {epoch}\")\n",
    "\n",
    "    train_loss, train_acc, train_preds, train_gts = train(model, device, train_loader, optimizer, epoch)\n",
    "    print(f\"Training Accuracy: {train_acc:.2f}% - Loss: {train_loss:.4f}\")\n",
    "\n",
    "    val_loss, val_acc, val_preds, val_gts = validation(model, device, val_loader)\n",
    "    print(f\"Validation Accuracy: {val_acc:.2f}% - Loss: {val_loss:.4f}\")\n",
    "\n",
    "    history[\"train_loss\"].append(train_loss)\n",
    "    history[\"train_acc\"].append(train_acc)\n",
    "    history[\"val_loss\"].append(val_loss)\n",
    "    history[\"val_acc\"].append(val_acc)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        save_best_model(model, optimizer, epoch, best_model_path)\n",
    "        print(f\"Best model updated at epoch {epoch} with loss {best_val_loss:.4f}\")\n",
    "\n",
    "# Save training history\n",
    "history_name = file_name + \".npy\"\n",
    "history_file = os.path.join(os.getcwd(), \"output\", history_name)\n",
    "np.save(history_file, history)\n",
    "print(f\"\\nTraining history saved at {history_file}\")\n",
    "\n",
    "cm_name = file_name + \".png\"\n",
    "test_and_save_confusion_matrix(model, device, test_loader, cm_name = cm_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "salvare come output combinazioni di training\n",
    "- window samples\n",
    "- window duration in seconds \n",
    "- window overlap in percentage \n",
    "- input features \n",
    "- pca \n",
    "- training accuracy\n",
    "- validation accuracy \n",
    "- test accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_and_save_confusion_matrix(model, device, loader):\n",
    "    model.eval()\n",
    "    gt_list = []\n",
    "    pred_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            # Ensure the input data is explicitly cast to float32\n",
    "            data = data.to(device).to(torch.float32)  \n",
    "            target = target.to(device).squeeze().long()\n",
    "            \n",
    "            output = model(data)  # Model forward pass\n",
    "            _, y_pred = torch.max(output, 1)  \n",
    "            \n",
    "            pred_list.append(y_pred)\n",
    "            gt_list.append(target)\n",
    "            \n",
    "        pred_list = torch.cat(pred_list)\n",
    "        gt_list = torch.cat(gt_list)\n",
    "      \n",
    "    test_acc = calculate_accuracy(pred_list, gt_list)\n",
    "    print(f\"Test Accuracy: {test_acc:.2f}%\")    \n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(gt_list.cpu().numpy(), pred_list.cpu().numpy())\n",
    "    num_classes = cm.shape[0]\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.arange(num_classes))\n",
    "\n",
    "    # Plot and save confusion matrix\n",
    "    disp.plot(cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.savefig('output/confusion_matrix.png')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.88%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_and_save_confusion_matrix(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_and_save_confusion_matrix(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

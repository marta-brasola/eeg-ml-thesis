{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path = \"/home/marta/Documenti/eeg-ml-thesis/\"\n",
    "os.chdir(path)\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim \n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import numpy as np \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import r_pca \n",
    "import scipy.io\n",
    "from tqdm import tqdm\n",
    "import datetime \n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay \n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = \"/home/marta/Documenti/eeg_rnn_repo/rnn-eeg-ad/eeg2\"\n",
    "WINDOW = 256\n",
    "OVERLAP = WINDOW // 2 \n",
    "subj_list = (\n",
    "    tuple((f'{i:02d}', 'N') for i in range(1, 16)) +  # normal subjects, S01 to S15\n",
    "    tuple((f'{i:02d}', 'AD') for i in range(1, 21))   # alzheimer's subjects, S01 to S20\n",
    ")\n",
    "\n",
    "input_dim = 16        \n",
    "hidden_dim = 8        \n",
    "output_dim = 2    \n",
    "window_size = 20      \n",
    "dropout_prob = 0.5 \n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "subjs_test = (0, 1, 15, 16, 17)  \n",
    "test_subject_list = [subj_list[i] for i in subjs_test]\n",
    "train_val_subjects = [subj for i, subj in enumerate(subj_list) if i not in subjs_test]   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copute Crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def precompute_crops(subject_list, window, overlap, num_columns=16, train_dataset=None):\n",
    "    \n",
    "\n",
    "    if train_dataset == True:\n",
    "        save_dir = \"/home/marta/Documenti/eeg-ml-thesis/alessandrini-train\"\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "    elif train_dataset == False:\n",
    "        save_dir = \"/home/marta/Documenti/eeg-ml-thesis/alessandrini-test\"\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    for subject_id, category_label in subject_list:\n",
    "        file_path = f\"{DATASET_DIR}/S{subject_id}_{category_label}.npz\"\n",
    "        save_path = f\"{save_dir}/S{subject_id}_{category_label}_crops.npz\"\n",
    "\n",
    "        # if os.path.exists(save_path): \n",
    "        #    print(f\"Skipping {subject_id}, crops already exist.\")\n",
    "        #    continue\n",
    "\n",
    "        eeg = np.load(file_path)['eeg'].T \n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        eeg = scaler.fit_transform(eeg)\n",
    "\n",
    "        num_windows = (len(eeg) - window) // (window - overlap) + 1\n",
    "        x_data = np.empty((num_windows, window, num_columns))\n",
    "\n",
    "        i = 0\n",
    "        for w in range(num_windows):\n",
    "            x_data[w] = eeg[i:i + window]\n",
    "            i += (window - overlap)\n",
    "\n",
    "        y_data = np.full((num_windows, 1), (category_label == 'AD')) \n",
    "\n",
    "        np.savez(save_path, x_data=x_data, y_data=y_data)\n",
    "        # print(f\"Saved crops for {subject_id} at {save_path}\")\n",
    "\n",
    "\n",
    "precompute_crops(train_val_subjects, window=WINDOW, overlap=OVERLAP, train_dataset=True)\n",
    "precompute_crops(test_subject_list, window=WINDOW, overlap=OVERLAP, train_dataset=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_val(dataset, test_size=0.2, random_state=42):\n",
    "    train_indices, val_indices = train_test_split(\n",
    "        range(len(dataset.crops_index)), \n",
    "        test_size=test_size,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    return train_indices, val_indices \n",
    "\n",
    "def pca_reduction(A, tol, comp = 0):\n",
    "  rpca = False\n",
    "  rpca_mu = 0\n",
    "  multiscale_pca = False\n",
    "\n",
    "  assert(len(A.shape) == 2)\n",
    "  dmin = min(A.shape)\n",
    "  if rpca:\n",
    "    r = r_pca.R_pca(A, mu = rpca_mu)\n",
    "    print('Auto tol:', 1e-7 * r.frobenius_norm(r.D), 'used tol:', tol)\n",
    "    print('mu', r.mu, 'lambda', r.lmbda)\n",
    "    L, S = r.fit(tol = tol, max_iter = 10, iter_print = 1)\n",
    "    global norm_s\n",
    "    norm_s = np.linalg.norm(S, ord='fro')  # for debug\n",
    "    print('||A,L,S||:', np.linalg.norm(A, ord='fro'), np.linalg.norm(L, ord='fro'), np.linalg.norm(S, ord='fro'))\n",
    "    #np.savez_compressed('rpca.npz', pre = A, post = L)\n",
    "  elif multiscale_pca:\n",
    "    print('MSPCA...')\n",
    "    #ms = mspca.MultiscalePCA()\n",
    "    #L = ms.fit_transform(A, wavelet_func='sym4', threshold=0.1, scale = True )\n",
    "    print('saving MAT file and calling Matlab...')\n",
    "    scipy.io.savemat('mspca.mat', {'A': A}, do_compression = True)\n",
    "    os.system('matlab -batch \"mspca(\\'mspca.mat\\')\"')\n",
    "    L = scipy.io.loadmat('mspca.mat')['L'] \n",
    "  else:\n",
    "    \n",
    "    L = A\n",
    "  U, lam, V = np.linalg.svd(L, full_matrices = False)  # V is transposed\n",
    "  assert(U.shape == (A.shape[0], dmin) and lam.shape == (dmin,) and V.shape == (dmin, A.shape[1]))\n",
    "  #np.savetxt('singular_values.csv', lam)\n",
    "  lam_trunc = lam[lam > 0.015 * lam[0]]  # magic number\n",
    "  p = comp if comp else len(lam_trunc)\n",
    "  assert(p <= dmin)\n",
    "  #print('PCA truncation', dmin, '->', p)\n",
    "  return L, V.T[:,:p]\n",
    "\n",
    "def reduce_matrix(A, V):\n",
    "  # (N, w, 16) → (N, 16, w) → ((N*16), w) → compute V\n",
    "  # (N, 16, w) * V → transpose again last dimensions\n",
    "  B = np.swapaxes(A, 1, 2)  # (N, 16, w)\n",
    "  C = B.reshape((-1, B.shape[2]))  # ((N*16), w)\n",
    "  if V is None:\n",
    "    L, V = pca_reduction(C, 5e-6, comp = 50)\n",
    "  B = C @ V  # ((N*16), p)\n",
    "  B = B.reshape((A.shape[0], A.shape[2], B.shape[1]))  # (N, 16, p)\n",
    "  return np.swapaxes(B, 1, 2), V  # B = (N, p, 16)\n",
    "\n",
    "def adjust_size(x, y):\n",
    "  # when flattening the data matrix on the first dimension, y must be made compatible\n",
    "  if len(x) == len(y): return y\n",
    "  factor = len(x) // len(y)\n",
    "  ynew = np.empty((len(x), 1))\n",
    "  for i in range(0, len(y)):\n",
    "    ynew[i * factor : (i + 1) * factor] = y[i]\n",
    "  return ynew\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling\n",
    "\n",
    "Oversampling only on trainig dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversampling(x_data, y_data, num_classes=2):\n",
    "  # Duplicate inputs with classes occurring less, so to have a more balanced distribution.\n",
    "  # It operates on single data windows, so use it on data that have already been split\n",
    "  #  by subject (typically only on training data).\n",
    "  x_data_over = x_data.copy()\n",
    "  y_data_over = y_data.copy()\n",
    "  occurr = [np.sum(y_data == cl) for cl in range(0, num_classes)]\n",
    "  for cl in range(0, num_classes):\n",
    "    if occurr[cl] == max(occurr):\n",
    "      continue\n",
    "    mask = y_data[:, 0] == cl\n",
    "    x_dup = x_data[mask].copy()\n",
    "    y_dup = y_data[mask].copy()\n",
    "    while occurr[cl] < max(occurr):\n",
    "      x_dup_jitter = x_dup + np.random.normal(scale=0.03, size=x_dup.shape)\n",
    "      how_many = min(len(y_dup), max(occurr) - occurr[cl])\n",
    "      x_data_over = np.vstack((x_data_over, x_dup_jitter[:how_many]))\n",
    "      y_data_over = np.vstack((y_data_over, y_dup[:how_many]))\n",
    "      occurr[cl] += how_many\n",
    "  return x_data_over, y_data_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: (40602, 256, 16), Labels distribution: [16290 24312]\n",
      "Oversampled dataset size: (48624, 256, 16), Labels distribution: [24312 24312]\n"
     ]
    }
   ],
   "source": [
    "path = \"/home/marta/Documenti/eeg-ml-thesis/alessandrini-train\"\n",
    "\n",
    "x_all = []\n",
    "y_all = []\n",
    "\n",
    "for file in os.listdir(path):\n",
    "    if file.endswith(\".npz\"):  \n",
    "        file_path = os.path.join(path, file)\n",
    "        data = np.load(file_path)\n",
    "        \n",
    "        x_all.append(data['x_data'])  \n",
    "        y_all.append(data['y_data'])  \n",
    "\n",
    "x_all = np.vstack(x_all)  \n",
    "y_all = np.vstack(y_all)\n",
    "\n",
    "print(f\"Original dataset size: {x_all.shape}, Labels distribution: {np.bincount(y_all.flatten())}\")\n",
    "\n",
    "x_all_over, y_all_over = oversampling(x_all, y_all)\n",
    "\n",
    "print(f\"Oversampled dataset size: {x_all_over.shape}, Labels distribution: {np.bincount(y_all_over.flatten())}\")\n",
    "\n",
    "x_all_over = torch.tensor(x_all_over).float()\n",
    "y_all_over = torch.tensor(y_all_over).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split and apply PCA\n",
    "- dovrei poter testare anche per diversi parametri di PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data shape: torch.Size([36468, 256, 16])\n",
      "training data shape: torch.Size([36468, 1])\n",
      "validation data shape: torch.Size([12156, 256, 16])\n",
      "validation data shape: torch.Size([12156, 1])\n"
     ]
    }
   ],
   "source": [
    "x_data_train, x_data_val, y_data_train, y_data_val = train_test_split(x_all_over, y_all_over, train_size = 0.75, random_state=42, shuffle=True)\n",
    "\n",
    "print(f\"training data shape: {x_data_train.shape}\")\n",
    "print(f\"training data shape: {y_data_train.shape}\")\n",
    "print(f\"validation data shape: {x_data_val.shape}\")\n",
    "print(f\"validation data shape: {y_data_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data shape: torch.Size([36468, 50, 16])\n",
      "training data shape: torch.Size([36468, 1])\n",
      "validation data shape: torch.Size([12156, 50, 16])\n",
      "validation data shape: torch.Size([12156, 1])\n"
     ]
    }
   ],
   "source": [
    "x_data_train, Vpca = reduce_matrix(x_data_train, None)\n",
    "y_data_train = adjust_size(x_data_train, y_data_train)\n",
    "\n",
    "x_data_val, _ = reduce_matrix(x_data_val, Vpca)\n",
    "y_data_val = adjust_size(x_data_val, y_data_val)\n",
    "\n",
    "print(f\"training data shape: {x_data_train.shape}\")\n",
    "print(f\"training data shape: {y_data_train.shape}\")\n",
    "print(f\"validation data shape: {x_data_val.shape}\")\n",
    "print(f\"validation data shape: {y_data_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlessandriniEegDataset(Dataset):\n",
    "    def __init__(self, x_data, y_data):\n",
    "        self.x_data = x_data\n",
    "        self.y_data = y_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x_data[idx], self.y_data[idx]\n",
    "\n",
    "train_dataset = AlessandriniEegDataset(x_data_train, y_data_train)\n",
    "val_dataset = AlessandriniEegDataset(x_data_val, y_data_val)\n",
    "test_dataset = AlessandriniEegDataset(x_data_val, y_data_val)\n",
    "\n",
    "#train_indices, val_indices = split_train_val(dataset_over, test_size=0.2)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers=1, dropout_prob=0.5):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        \n",
    "        ##TODO aggiungere un layer di flatten per processare la sequenza in maniera temporale \n",
    "        self.lstm1 = nn.LSTM(input_dim, hidden_dim, num_layers=num_layers, batch_first=True)\n",
    "        \n",
    "        self.dropout1 = nn.Dropout(dropout_prob)\n",
    "        \n",
    "        self.lstm2 = nn.LSTM(hidden_dim, hidden_dim, num_layers=num_layers, batch_first=True)\n",
    "        \n",
    "        self.dropout2 = nn.Dropout(dropout_prob)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # layer di attivazione\n",
    "        \n",
    "        # x = x.squeeze(0)  \n",
    "        out, (hn, cn) = self.lstm1(x)\n",
    "        \n",
    "        out = self.dropout1(out)\n",
    "        \n",
    "        out, (hn, cn) = self.lstm2(out)\n",
    "        \n",
    "        out = self.dropout2(out[:, -1, :])  \n",
    "        \n",
    "        out = self.fc(out)\n",
    "        \n",
    "        # out = F.log_softmax(out, dim=1) uso la loss cross entropy\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers=1, dropout_prob=0.5, use_dense1=False):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        \n",
    "        # Optional Dense Layer Before LSTM (matches TensorFlow's `dense1`)\n",
    "        self.use_dense1 = use_dense1\n",
    "        if use_dense1:\n",
    "            self.dense1 = nn.Linear(input_dim, hidden_dim)\n",
    "        \n",
    "        # First LSTM Layer (returns full sequence if second LSTM exists)\n",
    "        self.lstm1 = nn.LSTM(hidden_dim if use_dense1 else input_dim, hidden_dim, num_layers=num_layers, \n",
    "                             batch_first=True, dropout=dropout_prob if num_layers > 1 else 0, \n",
    "                             bidirectional=False)\n",
    "\n",
    "        self.dropout1 = nn.Dropout(dropout_prob) \n",
    "\n",
    "        # Second LSTM Layer (if present, returns last output)\n",
    "        self.lstm2 = nn.LSTM(hidden_dim, hidden_dim, num_layers=num_layers, batch_first=True, \n",
    "                             dropout=dropout_prob if num_layers > 1 else 0) \n",
    "\n",
    "        self.dropout2 = nn.Dropout(dropout_prob)\n",
    "\n",
    "        # Fully Connected Output Layer (No Softmax, since CrossEntropyLoss expects logits)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.use_dense1:\n",
    "            x = self.dense1(x)\n",
    "        \n",
    "        # First LSTM layer\n",
    "        out, _ = self.lstm1(x)\n",
    "        out = self.dropout1(out)\n",
    "\n",
    "        # Second LSTM layer (keeps last output only)\n",
    "        out, _ = self.lstm2(out)\n",
    "        out = self.dropout2(out[:, -1, :])  # Keep only last timestep\n",
    "        \n",
    "        # Fully connected output\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out  # No softmax, since PyTorch's CrossEntropyLoss applies it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_pred, y_true):\n",
    "  \n",
    "  correct = (y_pred == y_true).sum().item()\n",
    "  \n",
    "  return correct / y_true.size(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "  print(\"starting training loop\")\n",
    "  \n",
    "  \"\"\"\n",
    "  Define Training Step\n",
    "  \"\"\"\n",
    "  \n",
    "  model.train()\n",
    "  \n",
    "  train_loss = 0.0\n",
    "  pred_list = []\n",
    "  gt_list = []\n",
    "  \n",
    "  \n",
    "  for batch_idx, (data, target) in enumerate(tqdm(train_loader)):\n",
    "\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    output = model(data)\n",
    "    \n",
    "\n",
    "    target = target.squeeze().long()\n",
    "\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    loss = criterion(output, target)\n",
    "    train_loss += loss.item()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    _, y_pred = torch.max(output,1)\n",
    "    \n",
    "    pred_list.append(y_pred)\n",
    "    gt_list.append(target)\n",
    "    \n",
    "  pred_list = torch.cat(pred_list)\n",
    "  gt_list = torch.cat(gt_list)\n",
    "  \n",
    "  train_acc = calculate_accuracy(pred_list, gt_list) \n",
    "  print(\"ended training step\")\n",
    "  return train_loss / len(train_loader), train_acc, pred_list, gt_list \n",
    "\n",
    "def validation(model, device, val_loader):\n",
    "  print(\"starting validation step\")\n",
    "  \n",
    "  \"\"\"\n",
    "  Define Validation Step\n",
    "  \"\"\"\n",
    "    \n",
    "  model.eval()\n",
    "  \n",
    "  val_loss = 0   \n",
    "  pred_list = []\n",
    "  gt_list = []\n",
    "\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  \n",
    "  with torch.no_grad():\n",
    "    \n",
    "    for data, target in val_loader:\n",
    "        \n",
    "      data, target = data.to(device), target.to(device).squeeze().long()\n",
    "      output = model(data)\n",
    "      loss = criterion(output, target)\n",
    "      val_loss += loss.item()\n",
    "      _, y_pred = torch.max(output,1)\n",
    "      \n",
    "      pred_list.append(y_pred)\n",
    "      gt_list.append(target)\n",
    "      # correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "      \n",
    "  pred_list = torch.cat(pred_list)\n",
    "  gt_list = torch.cat(gt_list)\n",
    "           \n",
    "  val_acc = calculate_accuracy(pred_list, gt_list)\n",
    "  \n",
    "  \n",
    "  return val_loss / len(val_loader.dataset), val_acc, pred_list, gt_list \n",
    "     \n",
    "\n",
    "def test_and_save_confusion_matrix(model, device, loader):\n",
    "    model.eval()\n",
    "    gt_list = []\n",
    "    pred_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device).squeeze().long()\n",
    "            output = model(data)\n",
    "            _, y_pred = torch.max(output, 1)  \n",
    "            \n",
    "            pred_list.append(y_pred)\n",
    "            gt_list.append(target)\n",
    "            \n",
    "        pred_list = torch.cat(pred_list)\n",
    "        gt_list = torch.cat(gt_list)\n",
    "        \n",
    "    print(pred_list)\n",
    "    print(gt_list)\n",
    "    test_acc = calculate_accuracy(pred_list, gt_list)\n",
    "    print(f\"Test Accuracy: {test_acc:.2f}%\")    \n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(gt_list.cpu().numpy(), pred_list.cpu().numpy())\n",
    "    num_classes = cm.shape[0]\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.arange(num_classes))\n",
    "\n",
    "    # Plot and save confusion matrix\n",
    "    disp.plot(cmap='viridis')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.savefig('output/confusion_matrix.png')\n",
    "    plt.show()   \n",
    "         \n",
    "def save_model(model, optimizer, epoch):\n",
    "    \"\"\"\n",
    "    Function to save model states for a given epoch.\n",
    "    \"\"\"\n",
    "    \n",
    "    model_name = model.__class__.__name__\n",
    "\n",
    "    model_dir = os.path.join(os.getcwd(), \"output\")\n",
    "    os.makedirs(model_dir, exist_ok=True)  # Creates directory if it doesn't exist\n",
    "\n",
    "    # Generate filename with timestamp\n",
    "    now = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    path = os.path.join(model_dir, f\"{model_name}_{now}.pth\")  # Add `.pth` for clarity\n",
    "\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "    }, path)\n",
    "\n",
    "    print(f\"Model saved to {path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch number: 1\n",
      "starting training loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1140 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1140/1140 [00:07<00:00, 153.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ended training step\n",
      "train_preds: tensor([0, 0, 0,  ..., 1, 1, 0], device='cuda:0')\n",
      "train_gts tensor([0, 1, 0,  ..., 1, 1, 0], device='cuda:0')\n",
      "training accuracy: 0.563864209718109\n",
      "starting validation step\n",
      "train_preds: tensor([0, 1, 0,  ..., 1, 0, 0], device='cuda:0')\n",
      "train_gts tensor([1, 1, 0,  ..., 1, 0, 0], device='cuda:0')\n",
      "validation accuracy: 0.7639848634419217\n",
      "Model saved to /home/marta/Documenti/eeg-ml-thesis/output/LSTMModel_20250223_163814.pth\n"
     ]
    }
   ],
   "source": [
    "model = LSTMModel(input_dim, hidden_dim, output_dim, dropout_prob=dropout_prob, use_dense1=False)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "# scheduler = StepLR(optimizer, step_size=1)\n",
    "num_epochs = 2\n",
    "for epoch in range(1, num_epochs):\n",
    "  print(f\"Processing epoch number: {epoch}\")\n",
    "  train_loss, train_acc, train_preds, train_gts = train(model=model, device=device, train_loader=train_loader, optimizer=optimizer, epoch=epoch)\n",
    "\n",
    "  print(f\"train_preds: {train_preds}\")\n",
    "  print(f\"train_gts {train_gts}\")\n",
    "  print(f\"training accuracy: {train_acc}\")\n",
    "\n",
    "  val_loss, val_acc, val_preds, val_gts = validation(model, device, val_loader)\n",
    "  print(f\"train_preds: {val_preds}\")\n",
    "  print(f\"train_gts {val_gts}\")\n",
    "  print(f\"validation accuracy: {val_acc}\")\n",
    "  \n",
    "  save_model(model, optimizer, epoch)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/marta/Documenti/eeg-ml-thesis/alessandrini-test\"\n",
    "\n",
    "x_test_all = []\n",
    "y_test_all = []\n",
    "\n",
    "for file in os.listdir(path):\n",
    "    if file.endswith(\".npz\"):  \n",
    "        file_path = os.path.join(path, file)\n",
    "        data = np.load(file_path)\n",
    "        \n",
    "        x_test_all.append(data['x_data'])  \n",
    "        y_test_all.append(data['y_data'])  \n",
    "\n",
    "x_test_all = np.vstack(x_test_all)\n",
    "y_test_all = np.vstack(y_test_all)\n",
    "\n",
    "\n",
    "x_data_test, _ = reduce_matrix(x_test_all, Vpca.cpu().numpy() if isinstance(Vpca, torch.Tensor) else Vpca)\n",
    "\n",
    "y_data_test = adjust_size(x_data_test, y_test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 1,  ..., 1, 1, 1], device='cuda:0')\n",
      "tensor([0, 1, 1,  ..., 1, 0, 1], device='cuda:0')\n",
      "Test Accuracy: 0.93%\n"
     ]
    }
   ],
   "source": [
    "def test_and_save_confusion_matrix(model, device, loader):\n",
    "    model.eval()\n",
    "    gt_list = []\n",
    "    pred_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device).squeeze().long()\n",
    "            output = model(data)\n",
    "            _, y_pred = torch.max(output, 1)  \n",
    "            \n",
    "            pred_list.append(y_pred)\n",
    "            gt_list.append(target)\n",
    "            \n",
    "        pred_list = torch.cat(pred_list)\n",
    "        gt_list = torch.cat(gt_list)\n",
    "        \n",
    "    print(pred_list)\n",
    "    print(gt_list)\n",
    "    test_acc = calculate_accuracy(pred_list, gt_list)\n",
    "    print(f\"Test Accuracy: {test_acc:.2f}%\") \n",
    "  \n",
    "\n",
    "test_and_save_confusion_matrix(model, device, test_loader) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 0,  ..., 0, 1, 0], device='cuda:0')\n",
      "tensor([1, 1, 0,  ..., 0, 1, 0], device='cuda:0')\n",
      "Test Accuracy: 0.93%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_data_test = x_data_test.astype(np.float32)  \n",
    "\n",
    "test_dataset = AlessandriniEegDataset(x_data_test, y_data_test)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "test_and_save_confusion_matrix(model, device, test_loader) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

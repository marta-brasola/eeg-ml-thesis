{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA, IncrementalPCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "aless_path = \"/home/marta/Documenti/eeg_rnn_repo/rnn-eeg-ad/eeg2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(window, overlap, decimation_factor = 0):\n",
    "  # Create the input and target data from dataset,\n",
    "  # according to window and overlap\n",
    "  # new dataset 4 dec 2021\n",
    "  # 15 N, 20 AD (resulting indexes: N = 0..14, AD = 15..34)\n",
    "  #Common signals: ['EEG Fp1', 'EEG Fp2', 'EEG F7', 'EEG F3', 'EEG F4', 'EEG F8', 'EEG T3', 'EEG C3', 'EEG C4', 'EEG T4', 'EEG T5', 'EEG P3', 'EEG P4', 'EEG T6', 'EEG O1', 'EEG O2']\n",
    "\n",
    "#   tf.random.set_seed(42)\n",
    "  np.random.seed(42)\n",
    "  dataset_dir = aless_path\n",
    "  subj_list = tuple((f'{i:02d}', 'N') for i in range(1, 16)) + tuple((f'{i:02d}', 'AD') for i in range(1, 21))\n",
    "  print(subj_list)\n",
    "  num_columns = 16\n",
    "\n",
    "  x_data = np.empty((0, window, num_columns))\n",
    "  y_data = np.empty((0, 1))  # labels\n",
    "  subj_inputs = []  # number of inputs for every subject\n",
    "  print('\\n### creating dataset')\n",
    "  tot_rows = 0\n",
    "  for subject in subj_list:\n",
    "    subj_inputs.append(0)\n",
    "    category = ('N', 'AD').index(subject[1])\n",
    "    eeg = np.load(f'{dataset_dir}/S{subject[0]}_{subject[1]}.npz')['eeg'].T\n",
    "    # if spikes: eeg = set_holes(eeg, spikes)\n",
    "    #scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    scaler = StandardScaler()\n",
    "    eeg = scaler.fit_transform(eeg)\n",
    "    assert(eeg.shape[1] == num_columns)\n",
    "    tot_rows += len(eeg)\n",
    "    # decimation (optional)\n",
    "    if decimation_factor:\n",
    "      eeg2 = np.empty((eeg.shape[0] // decimation_factor, eeg.shape[1]))\n",
    "      for col in range(0, num_columns):\n",
    "        #tmp = scipy.signal.decimate(fusion[:, col], decimation_factor)\n",
    "        tmp = eeg[:, col][::decimation_factor]  # simpler method\n",
    "        eeg2[:, col] = tmp[:len(eeg2)]\n",
    "      eeg = eeg2\n",
    "    # windowing\n",
    "    # compute number of windows (lazy way)\n",
    "    i = 0\n",
    "    num_w = 0\n",
    "    while i + window  <= len(eeg):\n",
    "      i += (window - overlap)\n",
    "      num_w += 1\n",
    "    # compute actual windows\n",
    "    x_data_part = np.empty((num_w, window, num_columns))  # preallocate\n",
    "    i = 0\n",
    "    for w in range(0, num_w):\n",
    "      x_data_part[w] = eeg[i:i + window]\n",
    "      i += (window - overlap)\n",
    "      if False: # watermark provenience of every window\n",
    "        for cc in range(0, num_columns):\n",
    "          x_data_part[w, 0, cc] = 1000 * (len(subj_inputs) - 1) + cc\n",
    "    x_data = np.vstack((x_data, x_data_part))\n",
    "    y_data = np.vstack((y_data, np.full((num_w, 1), category)))\n",
    "    subj_inputs[-1] += num_w\n",
    "\n",
    "  print('\\ntot samples:', tot_rows)\n",
    "  print('x_data:', x_data.shape)\n",
    "  print('y_data:', y_data.shape)\n",
    "  print('windows per subject:', subj_inputs)\n",
    "#   print('class distribution:', [np.sum(y_data == cl) for cl in range(0, num_classes)])\n",
    "\n",
    "  return x_data, y_data, subj_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP pca Alessandrini \n",
    "- np.swapaxes(A, 1, 2)  # (N, 16, w)\n",
    "- reshape((-1, B.shape[2]))  # ((N*16), w)\n",
    "- funzione pca_reduction con custom PCA class \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parametri default alessandrini \n",
    "\n",
    "pca = True\n",
    "rpca = False ## viene usata solo in caso di training con i dati corrotti \n",
    "multiscale_pca = False \n",
    "\n",
    "\n",
    "def reduce_matrix(A, V):\n",
    "  # (N, w, 16) → (N, 16, w) → ((N*16), w) → compute V\n",
    "  # (N, 16, w) * V → transpose again last dimensions\n",
    "  B = np.swapaxes(A, 1, 2)  # (N, 16, w)\n",
    "  C = B.reshape((-1, B.shape[2]))  # ((N*16), w)\n",
    "  if V is None:\n",
    "    L, V = pca_reduction(C, 5e-6, comp = 50) \n",
    "  B = C @ V  # ((N*16), p)\n",
    "  B = B.reshape((A.shape[0], A.shape[2], B.shape[1]))  # (N, 16, p)\n",
    "  return np.swapaxes(B, 1, 2), V  # B = (N, p, 16)\n",
    "\n",
    "\n",
    "def adjust_size(x, y):\n",
    "  # when flattening the data matrix on the first dimension, y must be made compatible\n",
    "  if len(x) == len(y): return y\n",
    "  factor = len(x) // len(y)\n",
    "  ynew = np.empty((len(x), 1))\n",
    "  for i in range(0, len(y)):\n",
    "    ynew[i * factor : (i + 1) * factor] = y[i]\n",
    "  return ynew\n",
    "\n",
    "def pca_reduction(A, tol, comp = 0):\n",
    "  assert(len(A.shape) == 2)\n",
    "  dmin = min(A.shape)\n",
    "  \n",
    "  \n",
    "  if rpca:\n",
    "    r = r_pca.R_pca(A, mu = rpca_mu)\n",
    "    print('Auto tol:', 1e-7 * r.frobenius_norm(r.D), 'used tol:', tol)\n",
    "    print('mu', r.mu, 'lambda', r.lmbda)\n",
    "    L, S = r.fit(tol = tol, max_iter = 10, iter_print = 1)\n",
    "    global norm_s\n",
    "    norm_s = np.linalg.norm(S, ord='fro')  # for debug\n",
    "    print('||A,L,S||:', np.linalg.norm(A, ord='fro'), np.linalg.norm(L, ord='fro'), np.linalg.norm(S, ord='fro'))\n",
    "    #np.savez_compressed('rpca.npz', pre = A, post = L)\n",
    "  elif multiscale_pca:\n",
    "    print('MSPCA...')\n",
    "    #ms = mspca.MultiscalePCA()\n",
    "    #L = ms.fit_transform(A, wavelet_func='sym4', threshold=0.1, scale = True )\n",
    "    print('saving MAT file and calling Matlab...')\n",
    "    scipy.io.savemat('mspca.mat', {'A': A}, do_compression = True)\n",
    "    os.system('matlab -batch \"mspca(\\'mspca.mat\\')\"')\n",
    "    L = scipy.io.loadmat('mspca.mat')['L'] \n",
    "  else:\n",
    "    L = A\n",
    "  U, lam, V = np.linalg.svd(L, full_matrices = False)  # V is transposed\n",
    "  assert(U.shape == (A.shape[0], dmin) and lam.shape == (dmin,) and V.shape == (dmin, A.shape[1]))\n",
    "  #np.savetxt('singular_values.csv', lam)\n",
    "  lam_trunc = lam[lam > 0.015 * lam[0]]  # magic number\n",
    "  p = comp if comp else len(lam_trunc)\n",
    "  assert(p <= dmin)\n",
    "  print('PCA truncation', dmin, '->', p)\n",
    "  return L, V.T[:,:p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation = ((2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34), ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_accuracy(y_pred: list, y_true: list):\n",
    "  \n",
    "  correct = (y_pred == y_true).sum().item()\n",
    "  \n",
    "  return correct / y_true.size(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected Tensor as element 0 in argument 0, but got int",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      2\u001b[0m y \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m----> 4\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected Tensor as element 0 in argument 0, but got int"
     ]
    }
   ],
   "source": [
    "y_pred = [1,1,0]\n",
    "y = [1,1,0]\n",
    "\n",
    "torch.cat(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('07', 'N'),\n",
       " ('09', 'AD'),\n",
       " ('09', 'N'),\n",
       " ('12', 'N'),\n",
       " ('08', 'AD'),\n",
       " ('10', 'AD'),\n",
       " ('08', 'N'),\n",
       " ('14', 'AD'),\n",
       " ('04', 'AD'),\n",
       " ('03', 'N'),\n",
       " ('04', 'N'),\n",
       " ('16', 'AD'),\n",
       " ('13', 'AD'),\n",
       " ('05', 'N'),\n",
       " ('06', 'N'),\n",
       " ('05', 'AD'),\n",
       " ('06', 'AD'),\n",
       " ('07', 'AD'),\n",
       " ('12', 'AD'),\n",
       " ('11', 'N'),\n",
       " ('15', 'AD'),\n",
       " ('11', 'AD'),\n",
       " ('10', 'N')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_subject_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_subject_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_pred == y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
